---
description: Standardized pattern for creating execution plans that deliver high-quality code through atomic iterations with continuous testing and strict git workflows
globs: 
alwaysApply: false
---

# Enterprise Execution Plan Pattern

This rule establishes a standardized methodology for creating comprehensive execution plans that ensure high-quality code delivery through atomic iterations, continuous testing, and proper version control workflows with immediate feedback loops.

## Prerequisites

Before creating execution plans, ensure:
- Project has established Git repository with main branch
- Development environment includes Node.js 20.x+, Git 2.30+, and PowerShell
- Quality foundations are in place (ESLint, Prettier, testing framework)
- Team understands conventional commits and feature branch workflows
- npm scripts are established for testing (test, lint, build, etc.)

## Core Principle

**ALWAYS break complex development initiatives into atomic iterations that follow strict branch-develop-test-develop-test-release cycles with continuous testing and immediate feedback loops to ensure enterprise-ready code delivery.**

## Execution Plan Structure Standard

### 1. Progress Tracking Dashboard (Required)

Every execution plan MUST start with a comprehensive progress dashboard:

```markdown
## üìä **PROGRESS TRACKING DASHBOARD**

### **Overall Status**
- **Current Iteration**: [ ] Iteration 1 | [ ] Iteration 2 | [ ] Iteration 3 | [ ] Iteration N
- **Overall Progress**: X% Complete (Y of Z iterations completed)  
- **Last Session Date**: [Current Date]
- **Status**: [Current Status Description]

### **Iteration Progress Summary**
| Iteration | Feature | Status | Duration Est. | Dependencies |
|-----------|---------|--------|---------------|--------------|
| **Iteration 1**: [Name] | Single feature | [ ] Not Started<br/>[ ] In Progress<br/>[ ] Completed | 2-4 hours | None |

### **Quick Iteration Status**
**Iteration 1 - [Feature Name]**
- [ ] Branch & Pull Latest
- [ ] Develop (Initial)
- [ ] Test (Level 1)
- [ ] Develop (Refine)
- [ ] Test (Level 2)
- [ ] Test Release (Level 3)
- [ ] Create PR & Merge

### **Session Quick Start**
```powershell
# Context Recovery Commands
Get-Location                    # Verify project directory
Test-Path package.json          # Confirm in correct project
git status                      # See current changes
git branch                      # Check current branch
npm run quality:check           # Quick validation
```
```

### 2. Plan Overview (Required)

Include comprehensive project context:

```markdown
## üìã **PLAN OVERVIEW**

### **Current State Assessment**
- **Project Type**: [Technology stack description]
- **Foundation Quality**: [Assessment of existing foundation]
- **Enterprise Readiness**: [Gap analysis]

### **Target State**
- **Primary Goals**: [Key objectives]
- **Standards Compliance**: [Rules/standards to achieve]
- **Success Metrics**: [Measurable outcomes]

### **Implementation Strategy**
- **Approach**: Atomic iterations with continuous testing
- **Workflow**: Branch ‚Üí Develop ‚Üí Test ‚Üí Develop ‚Üí Test ‚Üí Release ‚Üí PR
- **Session Support**: Plan designed for multi-session execution
- **Testing Integration**: Leverages npm scripts for consistent validation
```

### 3. Current State Analysis (Required)

Provide detailed gap analysis:

```markdown
## üîç **CURRENT STATE ANALYSIS**

### ‚úÖ **EXISTING STRENGTHS**
- [List current positive aspects]
- [Available npm scripts for testing]

### ‚ùå **CRITICAL GAPS IDENTIFIED**
**[Category Name] ([rule-reference.mdc])**
- [Specific gap description]
- [Impact assessment]
- [Testing approach needed]
```

### 4. Pattern Discovery & Consistency Analysis (MANDATORY)

**CRITICAL**: Before any implementation begins, developers MUST analyze existing patterns to ensure new features integrate seamlessly with established codebase conventions.

```markdown
## üîç **PATTERN DISCOVERY & CONSISTENCY ANALYSIS**

### **‚ö†Ô∏è MANDATORY PRE-IMPLEMENTATION ANALYSIS**

**Rule**: NO development may begin until this analysis is completed and documented with evidence.

### **üîé DISCOVER SIMILAR EXISTING FEATURES**

Before implementing any new feature, identify and analyze similar existing implementations:

```powershell
# Find similar feature implementations
Get-ChildItem -Path "src" -Recurse -Include "*.tsx","*.ts" | Select-String -Pattern "[SimilarFeatureName]" | Select-Object Filename,LineNumber,Line

# Analyze component structure patterns
Get-ChildItem -Path "src/components" -Directory | Format-Table Name

# Find existing modal, form, list, or table implementations
Get-ChildItem -Path "src/components" -Recurse -Include "*Modal*","*Form*","*List*","*Table*" | Select-Object Name,Directory

# Search for styling patterns and component usage
Select-String -Path "src/components/**/*.tsx" -Pattern "className.*=.*" | Select-Object Filename,LineNumber,Line | Format-List
```

### **üìã PATTERN ANALYSIS CHECKLIST**

**Similar Feature Identification:**
- [ ] **Feature Identified**: ________________________________
  - Location: ________________________________
  - Implementation approach: ________________________________
  - Component architecture used: ________________________________

**UI/UX Pattern Analysis:**
- [ ] **Modal vs Page Navigation**: What pattern does similar feature use?
  - Evidence: ________________________________
- [ ] **Button Styles**: What button components are used?
  - Evidence: ________________________________  
- [ ] **Form Patterns**: How are forms structured and validated?
  - Evidence: ________________________________
- [ ] **Table/List Display**: What components are used for data display?
  - Evidence: ________________________________
- [ ] **Search Functionality**: How is search implemented and styled?
  - Evidence: ________________________________

**Component Reuse Analysis:**
- [ ] **Existing Components**: What reusable components should be used?
  - Component: _____________ | Location: _____________
  - Component: _____________ | Location: _____________
  - Component: _____________ | Location: _____________
- [ ] **Styling Systems**: What styling patterns must be followed?
  - Evidence: ________________________________
- [ ] **Layout Containers**: What layout components are available?
  - Evidence: ________________________________

**Testing Pattern Analysis:**
- [ ] **Test File Structure**: How are tests organized in similar features?
  - Pattern: ________________________________
- [ ] **Mocking Patterns**: What mocking strategies are used?
  - Evidence: ________________________________
- [ ] **Test Utilities**: What test utilities and helpers exist?
  - Location: ________________________________

### **üéØ IMPLEMENTATION CONSTRAINTS DERIVED**

Based on pattern analysis, document MANDATORY implementation constraints:

**Architecture Constraints:**
- [ ] **Component Structure**: Must follow [pattern] as seen in [existing feature]
- [ ] **Navigation Pattern**: Must use [modal/page] approach like [existing feature]
- [ ] **State Management**: Must use [pattern] as established in [existing feature]

**UI/UX Constraints:**
- [ ] **Component Usage**: MUST use existing [Button/Table/Modal] components
- [ ] **Styling Approach**: MUST follow [specific styling pattern]
- [ ] **Layout Structure**: MUST use [specific layout components]

**Testing Constraints:**
- [ ] **Test Structure**: MUST follow [existing pattern] from [reference feature]
- [ ] **Mock Patterns**: MUST use [specific mocking approach]
- [ ] **Test Organization**: MUST place tests in [specific structure]

### **‚úÖ PATTERN COMPLIANCE VERIFICATION**

**PRE-DEVELOPMENT SIGN-OFF** (Required before ANY iteration begins):

- [ ] **Similar feature analyzed** with documented evidence
- [ ] **UI/UX patterns identified** and constraints documented  
- [ ] **Component reuse opportunities** mapped and documented
- [ ] **Testing patterns analyzed** and approach defined
- [ ] **Implementation constraints** clearly defined with evidence
- [ ] **Development approach** designed to integrate seamlessly with existing patterns

**‚ö†Ô∏è CRITICAL**: Development may NOT proceed to iterations until ALL items above are verified with evidence.
```

### 5. Iteration Structure (Required)

Each iteration MUST follow this standardized format:

```markdown
# üöÄ **ITERATION X: [FEATURE NAME]**

**Status**: [ ] Not Started | [ ] In Progress | [ ] Completed

## **ITERATION OVERVIEW**
[Description of single feature/component to implement]

**Duration Estimate**: 2-4 hours in single session
**Dependencies**: [Previous iteration or "None"]
**Scope**: Single, atomic, testable feature

## **üîÑ STRICT ITERATION WORKFLOW**

### **Step 1: Branch & Pull Latest**
```powershell
# Always start with fresh main
git checkout main
git pull origin main
git checkout -b feat/iterationX-feature-name
```

### **Step 2: Develop (Initial)**
- **FIRST**: Verify pattern compliance before writing ANY code
- **Pattern Compliance Check**: Confirm implementation uses identified existing components and patterns
- **Architecture Verification**: Ensure feature structure matches analyzed similar features
- Implement core feature logic following established patterns
- Focus on getting basic functionality working using existing component library
- **DO NOT write tests yet** - focus on implementation first
- **DO NOT create new components** if existing ones serve the purpose

### **Step 3: Test (Level 1 - Immediate Feedback)**
```powershell
npm run quality:check  # Lint + format + type check
npm run test:run       # Quick unit test execution (existing tests only)
```

### **Step 4: Develop (Refine)**
- Fix issues found in Level 1 testing
- Improve implementation based on feedback
- **Write comprehensive unit tests** for YOUR business logic and validation functions
- **Write Playwright E2E tests** following `@playwright-testing-standards.mdc` for UI iterations
- Follow existing test patterns in the project (Vitest, React Testing Library)
- Achieve 100% test coverage for new business logic

**Testing Focus**: Test YOUR code - business logic, validation functions, and custom logic. Do NOT test framework functionality (Prisma ORM, Next.js, React, etc.)

**E2E Testing Focus**: For UI iterations, implement Playwright tests following "One Test at a Time" development process to prevent delays

### **Step 5: Test (Level 2 - Integration Validation)**
```powershell
npm run test:coverage  # Unit tests with coverage (including new tests)
npm run build          # Verify compilation
```

### **Step 6: Test Release (Level 3 - Full Validation)**
```powershell
npm run test:all                # Complete unit + E2E tests
npm run validate:pre-docker     # Full validation pipeline
```

### **Step 6.5: Docker Deployment Validation**
```powershell
# Deploy to Docker and validate functionality
docker-compose up --build -d
docker-compose ps              # Verify all containers are running
docker-compose logs web --tail=50  # Check for deployment errors

# Validate iteration functionality in containerized environment
# [Specific validation steps for each iteration's features]
# Example: Test API endpoints with PowerShell, verify database connectivity, check UI rendering
# Use PowerShell syntax: Invoke-RestMethod -Uri "http://localhost:3000/api/endpoint" -Method GET

# Clean up Docker environment
docker-compose down
```

### **Step 6.8: Verify Completion Criteria (MANDATORY BEFORE PR)**

**üéØ SYSTEMATIC COMPLETION VERIFICATION**

Before creating any PR, ALL criteria must be explicitly verified with evidence:

```powershell
# Final test validation
npm run test:all                # All tests passing
npm run build                   # Clean build confirmation
npm run quality:check          # No linting/formatting issues
```

**‚ö†Ô∏è CRITICAL: MANDATORY COMPLETION CRITERIA CHECK**

**STEP 1: Review the "ITERATION X COMPLETION CRITERIA" section at the bottom of this iteration.**

Each iteration has a specific completion criteria section that MUST be verified:

```markdown
### üéØ ITERATION X COMPLETION CRITERIA
ALL items must be verified before creating PR:
- [ ] [Specific criteria for this iteration]
- [ ] [Another specific criteria]
- [ ] [Continue for all iteration criteria]
```

**STEP 2: Verify EVERY item in that section with evidence before proceeding.**

**ITERATION COMPLETION CRITERIA VERIFICATION:**

‚ö†Ô∏è **Go to the "üéØ ITERATION X COMPLETION CRITERIA" section below and check off EVERY item before proceeding.**

- [ ] **I have reviewed and verified ALL items in the "üéØ ITERATION X COMPLETION CRITERIA" section**
- [ ] **Every checkbox in that section is completed**
- [ ] **The iteration is ready for progress tracking and PR creation**

**REGRESSION & QUALITY VERIFICATION:**

- [ ] **No breaking changes** to existing functionality
  - Evidence: Existing test suite: ___/___ passing (same as baseline)
  
- [ ] **No performance degradation** in existing features
  - Evidence: _______________________________________________
  
- [ ] **All npm scripts working** (test, build, lint, format)
  - Evidence: _______________________________________________
  
- [ ] **TypeScript compilation clean** with no type errors
  - Evidence: _______________________________________________

**DOCUMENTATION & PLAN UPDATES:**

- [ ] **Execution plan updated** with iteration completion status
  - Evidence: Progress dashboard shows iteration marked complete
  
- [ ] **Implementation deviations documented** (if any)
  - Evidence: _______________________________________________
  
- [ ] **Next iteration dependencies** confirmed ready
  - Evidence: _______________________________________________

**FINAL SIGN-OFF:**

- [ ] **ALL completion criteria verified** in the iteration-specific section below
- [ ] **All regression and quality checks passed**
- [ ] **Iteration is COMPLETE** and ready for progress tracking update
- [ ] **Ready to proceed** with Step 7: Update Progress Tracking

**‚ö†Ô∏è DO NOT PROCEED TO PROGRESS TRACKING UNLESS ALL CHECKBOXES ABOVE ARE COMPLETED**

### **Step 7: Update Progress Tracking**
```powershell
# Update execution plan with iteration completion
# Mark iteration as completed in progress dashboard
# Update overall progress percentage
# Set next iteration as ready to begin
git add .cursor/instructions/003_plans/[plan-name].md
git commit -m "docs: update progress tracking for Iteration X completion"
```

### **Step 8: Create PR & Merge**
```powershell
# Push feature branch with concise commit
git add .
git commit -m "feat([scope]): [concise feature description]"
git push -u origin feat/iterationX-feature-name
```

**PR Summary (Copy for manual PR creation):**
```markdown
## [Feature Name]

**Type:** [Feature/Bugfix/Enhancement]
**Scope:** [Database/API/UI/etc.]

### Changes
- [Bullet point of main changes]
- [Another key change]
- [Additional important change]

### Testing
- [Testing approach and coverage]
- [Key test scenarios covered]
- All existing tests continue to pass

### Dependencies
- [Dependencies on previous iterations or external requirements]
```

```powershell
# After PR approval and merge, clean up
git checkout main
git pull origin main
git branch -d feat/iterationX-feature-name
```

## **üìã ITERATION X IMPLEMENTATION**

**Rule Reference**: `[rule-file.mdc]`

**Files to Create/Modify**:
- `[file-path]` (new/modify)

**Implementation Steps**:
1. [Specific implementation step with exact commands]
2. [Another step with validation checkpoints]

**Testing Strategy**:
- **Step 4 Focus**: Write tests for YOUR business logic and validation functions (NOT framework functionality)
- **Test Patterns**: Follow existing project test structure (Vitest, React Testing Library)
- **Coverage Goal**: Achieve 100% test coverage for YOUR custom business logic
- **Test Files**: Place tests in `__tests__` directories alongside source files
- **Testing Scope**: Focus on custom validation functions, business rules, and constraint helpers - avoid testing framework functionality (Prisma, Next.js, React)
- **E2E Testing**: For UI iterations, implement Playwright E2E tests following `@playwright-testing-standards.mdc`
- **Seed Data**: Add reference data to `prisma/seed-data.yaml` instead of hardcoding strings in implementation

**Regression Protection**:
- [ ] Existing functionality remains intact
- [ ] No breaking changes to previous iterations
- [ ] All existing tests continue to pass
- [ ] New functionality has comprehensive test coverage

**Commit Strategy**:
- Progressive commits during development
- Final commit: `feat([scope]): [concise feature description]`

### **üéØ ITERATION X COMPLETION CRITERIA**
ALL items must be verified before creating PR:
- [ ] Level 1 tests pass (quality:check, test:run) 
- [ ] **New unit tests written** with 100% coverage for new functionality
- [ ] **Playwright E2E tests implemented** (for UI iterations) following @playwright-testing-standards.mdc
- [ ] Level 2 tests pass (test:coverage, build) including new tests
- [ ] Level 3 tests pass (test:all, validate:pre-docker) 
- [ ] Docker deployment validation passes (containers start, functionality works)
- [ ] **All existing tests continue to pass** (no regression)
- [ ] **Test files follow project patterns** (Vitest, proper mocking)
- [ ] Feature is completely functional and isolated
- [ ] Documentation updated if needed
- [ ] Execution plan progress dashboard updated with iteration completion
```

### 5. Session Management Appendix (Required)

Include comprehensive session recovery procedures:

```markdown
## üìö **APPENDIX: SESSION MANAGEMENT**

### **Starting a New Session**
1. **Context Recovery**: Read progress dashboard and identify current iteration
2. **Git Status Check**: Verify branch and working directory status
3. **Status Check**: Update iteration checkboxes based on actual completion
4. **Environment Verification**: Run `npm run quality:check` for quick validation
5. **Iteration Identification**: Find next uncompleted iteration

### **Iteration Workflow (Per Session)**
1. **Branch & Pull** ‚Üí Start fresh from main: `git checkout main && git pull origin main`
2. **Create Branch** ‚Üí `git checkout -b feat/iterationX-feature-name`
3. **Develop** ‚Üí Implement initial feature functionality
4. **Test L1** ‚Üí `npm run quality:check && npm run test:run`
5. **Develop** ‚Üí Refine based on immediate feedback
6. **Test L2** ‚Üí `npm run test:coverage && npm run build`
7. **Test L3** ‚Üí `npm run test:all && npm run validate:pre-docker`
8. **Docker Validation** ‚Üí `docker-compose up --build -d` + feature validation
9. **‚ö†Ô∏è MANDATORY: Verify Completion Criteria** ‚Üí Review and verify EVERY item in the "üéØ ITERATION X COMPLETION CRITERIA" section
10. **Update Progress** ‚Üí Update execution plan and commit progress tracking changes
11. **Create PR** ‚Üí Push branch and create detailed pull request

### **Quality Gates (4-Level Testing Pyramid)**
- **Level 1**: Immediate feedback (quality:check, test:run)
- **Level 2**: Integration validation (test:coverage, build)
- **Level 3**: Release readiness (test:all, validate:pre-docker)
- **Level 4**: Docker deployment validation (containerized environment testing)

### **Emergency Recovery**
If issues occur during an iteration:
1. Check git status: `git status && git log --oneline -5`
2. Review test failures: Check npm script output logs
3. Run regression check: `npm run test:all` to verify no breaking changes
4. Consult specific rule documentation for guidance
5. Rollback to iteration start if needed: `git checkout main && git branch -D current-branch`

### **Session Continuity Rules**
- Each iteration should complete in a single session (2-4 hours)
- If incomplete, document exact stopping point in progress dashboard
- Always end sessions with a clean git state (committed or stashed)
- Next session starts with fresh main pull and context recovery
```

## Implementation Guidelines

### Iteration Design Rules
1. **Atomic scope** - Each iteration implements exactly one feature/component
2. **Single session completion** - 2-4 hours maximum per iteration
3. **Clear dependencies** - Each iteration builds on previous stable iterations
4. **Continuous testing** - 3-level testing pyramid throughout development
5. **Configuration over hardcoding** - Use `prisma/seed-data.yaml` for reference data instead of hardcoded strings
6. **PowerShell commands** - Use PowerShell syntax for HTTP testing and Windows-compatible commands in Docker validation

### Testing Integration Rules
1. **npm script consistency** - Always use project's established npm scripts
2. **Immediate feedback** - Level 1 tests after initial development (existing tests only)
3. **Test-driven refinement** - Write comprehensive unit tests during Step 4 refinement
4. **E2E testing requirement** - Write Playwright E2E tests for UI iterations following @playwright-testing-standards.mdc
5. **Integration validation** - Level 2 tests after refinements (including new tests)
6. **Release readiness** - Level 3 tests before PR creation
7. **Coverage requirement** - Achieve 100% test coverage for new functionality
8. **Pattern consistency** - Follow existing test patterns (Vitest, React Testing Library)

### Git Workflow Rules
1. **Fresh main pulls** - Always start iterations from latest main
2. **Feature branches** - Each iteration uses dedicated feature branch
3. **Continuous commits** - Commit after each develop-test cycle
4. **PR completion** - Every iteration ends with PR creation and merge
5. **Branch cleanup** - Remove feature branches after successful merge

### Regression Protection Rules
1. **Interface contracts** - Define clear boundaries between iterations
2. **Backward compatibility** - No iteration should break previous functionality
3. **Integration testing** - Verify existing features still work after changes
4. **Rollback readiness** - Each iteration is independently revertible

### Test Writing Rules (Step 4 Focus)
1. **Implementation first** - Write core functionality before tests (Steps 2-3)
2. **Business logic testing** - Write tests for YOUR custom code during Step 4 refinement phase
3. **Pattern consistency** - Follow existing test file structure and naming
4. **Coverage requirement** - Achieve 100% coverage for YOUR business logic (not framework code)
5. **Testing scope** - Test custom validation functions, business rules, and constraint helpers
6. **Framework exclusion** - Do NOT test Prisma ORM, Next.js, React, or other framework functionality
7. **Test placement** - Place tests in `__tests__` directories alongside source
8. **Test types** - Focus on unit tests for business logic; integration tests handled by E2E suite

## Validation Checklist for Execution Plans

Before finalizing any execution plan, verify:

- [ ] **Progress dashboard** provides complete iteration tracking
- [ ] **Current state analysis** identifies specific gaps with rule references
- [ ] **Pattern discovery analysis** completed with existing feature analysis and implementation constraints
- [ ] **Component reuse strategy** documented based on existing pattern analysis
- [ ] **UI/UX consistency requirements** identified and mandated
- [ ] **Testing pattern compliance** specified based on existing test structure
- [ ] **Playwright E2E testing** included for UI iterations with @playwright-testing-standards.mdc reference
- [ ] **Each iteration** has atomic scope, clear objectives, and completion criteria
- [ ] **üéØ COMPLETION CRITERIA sections** are comprehensive and specific for each iteration
- [ ] **Testing pyramid** includes Level 1, 2, and 3 validation using npm scripts
- [ ] **Test writing strategy** clearly specifies Step 4 as testing phase
- [ ] **Coverage requirements** mandate 100% coverage for new functionality
- [ ] **Test patterns** require following existing project structure (Vitest, etc.)
- [ ] **Completion criteria verification** includes Step 6.8 with mandatory review of iteration-specific criteria
- [ ] **Git workflow** includes fresh main pulls and PR creation
- [ ] **Session management** provides context recovery procedures
- [ ] **Regression protection** ensures backward compatibility
- [ ] **Validation commands** use project's established npm scripts

## Common Scenarios

### Scenario: Multi-Component Feature Development
**Guidance**: Create atomic iterations per component (API endpoint ‚Üí service layer ‚Üí UI component ‚Üí integration)
**Reasoning**: Each component can be tested independently and issues are isolated

### Scenario: Legacy System Modernization  
**Guidance**: One iteration per modernized subsystem while maintaining API contracts
**Reasoning**: Minimizes risk through small changes and preserves system stability

### Scenario: New Feature with Multiple Parts
**Guidance**: Break into atomic iterations: data model ‚Üí API ‚Üí business logic ‚Üí UI ‚Üí tests
**Reasoning**: Each iteration builds incrementally with immediate testing feedback

## Examples

‚úÖ **Recommended Execution Plan Structure:**
```markdown
# Feature Development Plan
## Progress Dashboard (with iteration checkboxes and session recovery)
## Plan Overview (current ‚Üí target state with npm script integration)
## Current State Analysis (strengths vs gaps with testing approach)
## Pattern Discovery & Consistency Analysis (MANDATORY - analyze existing similar features)
## Iteration 1: Data Model (single database table/schema)
## Iteration 2: API Endpoint (single route with validation)  
## Iteration 3: Business Logic (service layer for feature)
## Iteration 4: UI Component (single reusable component)
## Iteration 5: Integration (connect all parts with tests)
## Session Management Appendix
```

‚úÖ **Pattern Discovery Example (Athletes vs Age Groups):**
```markdown
## Pattern Discovery Analysis
**Similar Feature Identified**: Age Groups management at `src/components/age-group/`
**Implementation Constraints Derived**:
- MUST use modal-based workflow (not page navigation) like age-groups
- MUST use Table components from `src/components/ui/table/` like age-groups  
- MUST use Button component with icons like age-groups
- MUST use ComponentCard wrapper like age-groups
- MUST follow same search styling patterns as age-groups
- MUST use ref-based refresh mechanism for table updates
```

‚ùå **Avoid This Structure:**
```markdown
# Poor Plan (Missing Pattern Analysis)
- Phase 1: Build everything for authentication (too large)
- Phase 2: Add all database stuff (no testing until end)  
- Phase 3: Make UI and connect (breaking changes likely)
# Missing: No analysis of existing auth patterns, leads to disconnected implementation
```

‚ùå **Real-World Anti-Pattern (What We Fixed):**
```markdown
# Athletes Feature (Disconnected Implementation)
## Issues Caused by Missing Pattern Analysis:
- Athletes used page navigation while age-groups used modals ‚Üí UX inconsistency
- Athletes used plain HTML tables while age-groups used Table components ‚Üí styling disconnected
- Athletes used different button styles ‚Üí visual inconsistency
- Athletes used different search styling ‚Üí UI fragmentation
- Athletes lacked proper refresh mechanism ‚Üí functionality gaps

## Prevention: Pattern Discovery Would Have Identified:
- Age-groups as the reference implementation
- Modal-based workflow requirement
- Table component reuse requirement  
- Button component standardization need
- Search styling consistency requirement
- Ref-based refresh pattern requirement
```

---

**Note**: This pattern ensures systematic delivery of enterprise-quality code through atomic iterations, continuous testing with 3-level validation pyramid, and strict git workflows with immediate feedback loops while maintaining session continuity across development cycles. **CRITICAL**: The mandatory Pattern Discovery & Consistency Analysis phase prevents disconnected implementations by ensuring all new features integrate seamlessly with existing codebase patterns, components, and architectural decisions.
```

I've created a comprehensive execution plan pattern that establishes a standardized methodology for complex development projects. Here are the key principles extracted from the enterprise modernization master plan:

## üéØ **Key Pattern Elements**

### **1. Progress Tracking Dashboard**
- Real-time status tracking with checkboxes
- Phase progress summary table
- Session recovery commands
- Clear completion metrics

### **2. Incremental Phase Structure**
- Maximum 4 phases for manageability
- 2-4 focused tasks per phase
- Clear dependencies between phases
- Comprehensive validation criteria

### **3. Git Integration Workflow**
- Feature branch per phase
- Conventional commits per task
- Pull request gate per phase
- Branch cleanup procedures

### **4. Quality Gates**
- Specific validation criteria per task
- Test commands for verification
- Completion criteria per phase
- Emergency recovery procedures

### **5. Session Management**
- Context recovery procedures
- Multi-session execution support
- Progress state persistence
- Environment verification commands

## üöÄ **Benefits of This Pattern**

1. **Quality Assurance**: Every task has specific validation criteria and test commands
2. **Incremental Delivery**: Small, testable changes committed frequently
3. **Session Continuity**: Easy to resume work across multiple development sessions
4. **Risk Mitigation**: Clear rollback procedures and dependency management
5. **Team Collaboration**: Standardized structure enables consistent execution across team members

This pattern ensures that complex development initiatives are broken down into manageable, testable increments while maintaining enterprise-quality standards and proper version control workflows.